{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RandomForest.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkjubran/AutoEncoders/blob/master/RandomForest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzmEcNHzuBI3",
        "colab_type": "text"
      },
      "source": [
        "# Clone the Source GitHub Reporsitory \n",
        "We need to clone some source files to be used throughtout this tutorial from a GitHub reprository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmP4GrRNudXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ./MachineLearning\n",
        "!git clone https://github.com/mkjubran/MachineLearning.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIlzJbCpmo0R",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest (RF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrMDfwQQzBEn",
        "colab_type": "text"
      },
      "source": [
        "**Readings and Resources**\n",
        "\n",
        "[1] https://towardsdatascience.com/understanding-random-forest-58381e0602d2\n",
        "\n",
        "[2] https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOQvdG9QW1Yv",
        "colab_type": "text"
      },
      "source": [
        "# Case #1: Studying Hours and Passing Exams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7ietEiOzhNl",
        "colab_type": "text"
      },
      "source": [
        "In this section we will use **Random Forest** (RF) to infer whether a student will pass or fail an exam based on the number of hours the student spends preparing for the exam. A dataset for few students that includes the number of study hours and whether they pass (1) or fail (0) the exam. This is a binary classification problem that can be solved using **RF** as will be shown next."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RSwASngm9_9",
        "colab_type": "text"
      },
      "source": [
        "**Implementation**\n",
        "\n",
        "Read the input data (number of study hours and exam pass or fail) from the csv file (HoursPassExam.csv) file. Use the pandas library (https://pandas.pydata.org/) to read the data from the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQX2iq_fnJOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"./MachineLearning/5_random_forest/HoursPassExam.csv\")\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9j_pcYIQiYa",
        "colab_type": "text"
      },
      "source": [
        "To get some information about the read dataset including parameters and type of fields and features use the pandas info method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6XIJhyRQe5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJA9kY1o6_lr",
        "colab_type": "text"
      },
      "source": [
        "To view the dataset, we will use the scatter plot from matplotlib library as"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryh3BJOV7eo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(df['hours'],df['pass'],color = 'red', marker = '+')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39M2I3LU70dB",
        "colab_type": "text"
      },
      "source": [
        "As can be seen, the output (y) is binary; 0 for failing the exam and 1 for passing the exam. Also, the chances of passing the exam increases when the number of studying hours for the exam increases. Let us divide the dataset into training and testing datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uIoyL855AoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x = df[['hours']]\n",
        "y = df['pass']\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)\n",
        "print('size of test dataset = {}, size of traing data = {}, percentage = {}%'.format(len(x_test),len(x_train),len(x_test)*100/(len(x_test) + len(x_train))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3B2xf9y60Xm",
        "colab_type": "text"
      },
      "source": [
        "Next we will train the **RF** model and compute its accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBkR7WTW9T7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import ensemble\n",
        "model_rf = ensemble.RandomForestClassifier()\n",
        "model_rf.fit(x_train,y_train)\n",
        "ACC_train_rf = model_rf.score(x_train,y_train)\n",
        "ACC_test_rf = model_rf.score(x_test,y_test)\n",
        "print(ACC_train_rf)\n",
        "print(ACC_test_rf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvVgdbGPgyI4",
        "colab_type": "text"
      },
      "source": [
        "Let us try to compare **RF** with the other ML techqniues"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ttQnBZ7gyxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model_lr = LogisticRegression()\n",
        "model_lr.fit(x_train, y_train)\n",
        "ACC_train_lr = model_lr.score(x_train, y_train)\n",
        "ACC_test_lr = model_lr.score(x_test, y_test)\n",
        "\n",
        "## Decision Trees\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "model_dt = DecisionTreeClassifier()\n",
        "model_dt.fit(x_train, y_train)\n",
        "ACC_train_dt = model_dt.score(x_train, y_train)\n",
        "ACC_test_dt = model_dt.score(x_test, y_test)\n",
        "\n",
        "## Support Vector Machine\n",
        "from sklearn.svm import SVC \n",
        "model_svm = SVC()\n",
        "model_svm.fit(x_train, y_train)\n",
        "ACC_train_svm = model_svm.score(x_train, y_train)\n",
        "ACC_test_svm = model_svm.score(x_test, y_test)\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Accuracy', 'Logistic (%)' , 'DT (%)' , 'SVM (%)' , 'RF (%)'])\n",
        "t.add_row(['Training', ACC_train_lr*100, ACC_train_dt*100, ACC_train_svm*100, ACC_train_rf*100])\n",
        "t.add_row(['Testing', ACC_test_lr*100, ACC_test_dt*100, ACC_test_svm*100, ACC_test_rf*100])\n",
        "print(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH1COvVuXwR5",
        "colab_type": "text"
      },
      "source": [
        "# Case #2: HR Analysis\n",
        "\n",
        "In this section, we will analyze the data of employees of a company. This data includes some information about the employees who are working at the company and those who left the company. Our objective is to predict whether an existing employee would leave the company based on his/her current status. This will help us decide to offer the employee some incentives to keep him/her in the company. This could also be used to plan early to hire new employees. We will try to solve this problem using **Random Forest** (RF)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eR70Y6nbQYs",
        "colab_type": "text"
      },
      "source": [
        "**Implementation**\n",
        "\n",
        "Read the input data from the csv file (HR_comma_sep.csv) file. Dataset is downloaded from Kaggle. Link: https://www.kaggle.com/giripujar/hr-analytics. Use the pandas library (https://pandas.pydata.org/) to read the data from the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZrjhWA3YRcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "HR = pd.read_csv('./MachineLearning/5_random_forest/HR_comma_sep.csv')\n",
        "HR.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RpPISukQ7AW",
        "colab_type": "text"
      },
      "source": [
        "To get some information about the read dataset use the pandas info method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trVn1MFTQ7gq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HR.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEVwPozTbhm6",
        "colab_type": "text"
      },
      "source": [
        "Before applying classification to the data, we will explore and analyze the data to determine the features that influence the decision of the employee to remain or leave the company."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5PfSFCycBBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "left = HR[HR.left==1] ## employees who left the company \n",
        "No_left= left.shape[0]\n",
        "remain = HR[HR.left==0] ## employees who remain at the company \n",
        "No_remain = remain.shape[0]\n",
        "Per_left = No_left / (No_left + No_remain)\n",
        "\n",
        "print('No_left = {}, No_remain = {} , Percentage of left = {} %'.format(No_left,No_remain,Per_left*100))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R61IR-gJdNQQ",
        "colab_type": "text"
      },
      "source": [
        "About $23\\%$ employees left the company. Now, let us check which features are mostly affecting the decision of employees to leave or remain in the company. To do this, we will measure the average of each numeric feature for employees to remain or leave the company.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmI7sVO4d6vG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HR.groupby('left').mean() #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY7uKIrGeOIQ",
        "colab_type": "text"
      },
      "source": [
        "We may conclude the following from the table above: \\\\\n",
        "1- Employees who remain in the company has higher satisfaction_level and thus it is a good indicator for our regression/classifier (good feature) \\\\\n",
        "2- The last_evaluation, number of projects, and time_spend_company scores are almost independent of the employees remain or leave the company \\\\\n",
        "3- The average_montly_hours for employees who left the company are higher than those who remained which could be an indicator (good feature) \\\\\n",
        "4- The promotion_last_5years feature of employees remaining in the company is much higher than those left the company (good feature) \\\\\n",
        "5- Work_accident is also an indicator so it is a good feature.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MlXIibs9Z8R",
        "colab_type": "text"
      },
      "source": [
        "Let us also check the quality of the categories' features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0Rf5SjP6Ix8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.crosstab(HR.salary,HR.left)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWOZE5NBy5ru",
        "colab_type": "text"
      },
      "source": [
        "The salary table shows that emloyees with high salaries are more likely to stay in the company. So it is a good feature. To visualize this we make a bar plot as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xIPIbJ5965b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.crosstab(HR.salary,HR.left).plot(kind='bar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q0QfTZjzPs2",
        "colab_type": "text"
      },
      "source": [
        "We need also to investigate the department feature as follows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCHfkCyz-B-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.crosstab(HR.Department,HR.left).plot(kind='bar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rT1gQWr30YT0",
        "colab_type": "text"
      },
      "source": [
        "The department type has a minor effect on the decision of employees to stay or leave the company. It doesn't look a major factor and thus we will ignore this feature. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3okSyzEL8HzB",
        "colab_type": "text"
      },
      "source": [
        "Based on the above analysis, we will create the following table which includes only the good (important, major) features affecting employees decisions to stay or leave the company"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2I6qW3L5XS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HR_GF = HR[['left','satisfaction_level','average_montly_hours','Work_accident','promotion_last_5years', 'salary']]\n",
        "HR_GF.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fR496PVVYaA",
        "colab_type": "text"
      },
      "source": [
        "Let us plot this data for better visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glqeH5PrVYn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "HR_GF_0 = HR_GF[HR_GF['left'] == 0]\n",
        "HR_GF_1 = HR_GF[HR_GF['left'] == 1]\n",
        "\n",
        "fig, axes = plt.subplots(2, 4,figsize = (20,10))\n",
        "axes[0,0].scatter(HR_GF_0['satisfaction_level'], HR_GF_0['average_montly_hours'], color = 'blue', marker ='+')\n",
        "axes[0,0].set_xlabel('satisfaction_level')\n",
        "axes[0,0].set_ylabel('average_montly_hours')\n",
        "\n",
        "axes[0,1].scatter(HR_GF_0['satisfaction_level'], HR_GF_0['Work_accident'], color = 'blue', marker ='+')\n",
        "axes[0,1].set_xlabel('satisfaction_level')\n",
        "axes[0,1].set_ylabel('Work_accident')\n",
        "\n",
        "axes[0,2].scatter(HR_GF_0['satisfaction_level'], HR_GF_0['promotion_last_5years'], color = 'blue', marker ='+')\n",
        "axes[0,2].set_xlabel('satisfaction_level')\n",
        "axes[0,2].set_ylabel('promotion_last_5years')\n",
        "\n",
        "axes[0,3].scatter(HR_GF_0['satisfaction_level'], HR_GF_0['salary'], color = 'blue', marker ='+')\n",
        "axes[0,3].set_xlabel('satisfaction_level')\n",
        "axes[0,3].set_ylabel('salary')\n",
        "\n",
        "axes[1,0].scatter(HR_GF_1['satisfaction_level'], HR_GF_1['average_montly_hours'], color = 'orange', marker ='s')\n",
        "axes[1,0].set_xlabel('satisfaction_level')\n",
        "axes[1,0].set_ylabel('average_montly_hours')\n",
        "\n",
        "axes[1,1].scatter(HR_GF_1['satisfaction_level'], HR_GF_1['Work_accident'], color = 'orange', marker ='s')\n",
        "axes[1,1].set_xlabel('satisfaction_level')\n",
        "axes[1,1].set_ylabel('Work_accident')\n",
        "\n",
        "axes[1,2].scatter(HR_GF_1['satisfaction_level'], HR_GF_1['promotion_last_5years'], color = 'orange', marker ='s')\n",
        "axes[1,2].set_xlabel('satisfaction_level')\n",
        "axes[1,2].set_ylabel('promotion_last_5years')\n",
        "\n",
        "axes[1,3].scatter(HR_GF_1['satisfaction_level'], HR_GF_1['salary'], color = 'orange', marker ='s')\n",
        "axes[1,3].set_xlabel('satisfaction_level')\n",
        "axes[1,3].set_ylabel('salary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ho-hLuj1bTz",
        "colab_type": "text"
      },
      "source": [
        "By comparing the top and bottom figures, the dataset is separable with respect to the left feature.\n",
        "\n",
        "**For the RF algorithm** there is no need to apply one hot coding for categories features. However, we will need to convert them to numbers. We will use label encoder from sklearn library to encode the category feature (salary) as follows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4vXoCKhHwx9",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le_salary = LabelEncoder()\n",
        "HR_GF_LE = pd.DataFrame.copy(HR_GF)\n",
        "HR_GF_LE['salary'] = le_salary.fit_transform(HR_GF_LE['salary'])\n",
        "HR_GF_LE.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYVPPi0N4AR_",
        "colab_type": "text"
      },
      "source": [
        "Let us define input (x) and output (y) of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ercG4Iwd4A-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = HR_GF_LE.drop('left',axis=1)\n",
        "y = HR_GF_LE.left"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfEJ_b-i3Vee",
        "colab_type": "text"
      },
      "source": [
        "Before classification, we need to split the datset into test and training parts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTFsz9D_3oF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)\n",
        "print('size of test dataset = {}, size of traing data = {}, percentage = {}%'.format(len(x_test),len(x_train),len(x_test)*100/(len(x_test) + len(x_train))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRyJhrij4oAB",
        "colab_type": "text"
      },
      "source": [
        "Now, we are ready to apply **RF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wVAxuJm4pMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import ensemble\n",
        "HR_rf = ensemble.RandomForestClassifier()\n",
        "HR_rf.fit(x_train,y_train)\n",
        "ACC_train_rf = HR_rf.score(x_train,y_train)\n",
        "ACC_test_rf = HR_rf.score(x_test,y_test)\n",
        "print(ACC_train_rf)\n",
        "print(ACC_test_rf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMLQxxK36HRx",
        "colab_type": "text"
      },
      "source": [
        "Let us try to compare **RF** with the other ML techqniues\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqGCtp_Mrl_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## add column for logitic regression (training)\n",
        "dm = pd.get_dummies(x_train.salary)\n",
        "x_train_lr = pd.concat([x_train,dm],axis=1)\n",
        "x_train_lr = x_train_lr.drop(['salary',2],axis=1)\n",
        "## add column for logitic regression (testing)\n",
        "dm = pd.get_dummies(x_test.salary)\n",
        "x_test_lr = pd.concat([x_test,dm],axis=1)\n",
        "x_test_lr = x_test_lr.drop(['salary',2],axis=1)\n",
        "\n",
        "## logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model_lr = LogisticRegression()\n",
        "model_lr.fit(x_train_lr, y_train)\n",
        "ACC_train_lr = model_lr.score(x_train_lr, y_train)\n",
        "ACC_test_lr = model_lr.score(x_test_lr, y_test)\n",
        "\n",
        "## Decision Trees\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "model_dt = DecisionTreeClassifier()\n",
        "model_dt.fit(x_train, y_train)\n",
        "ACC_train_dt = model_dt.score(x_train, y_train)\n",
        "ACC_test_dt = model_dt.score(x_test, y_test)\n",
        "\n",
        "## Support Vector Machine\n",
        "from sklearn.svm import SVC \n",
        "model_svm = SVC()\n",
        "model_svm.fit(x_train, y_train)\n",
        "ACC_train_svm = model_svm.score(x_train, y_train)\n",
        "ACC_test_svm = model_svm.score(x_test, y_test)\n",
        "\n",
        "## Random Forest\n",
        "from sklearn import ensemble\n",
        "HR_rf = ensemble.RandomForestClassifier()\n",
        "HR_rf.fit(x_train,y_train)\n",
        "ACC_train_rf = HR_rf.score(x_train,y_train)\n",
        "ACC_test_rf = HR_rf.score(x_test,y_test)\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Accuracy', 'Logistic (%)' , 'DT (%)' , 'SVM (%)' , 'RF (%)'])\n",
        "t.add_row(['Training', ACC_train_lr*100, ACC_train_dt*100, ACC_train_svm*100, ACC_train_rf*100])\n",
        "t.add_row(['Testing', ACC_test_lr*100, ACC_test_dt*100, ACC_test_svm*100, ACC_test_rf*100])\n",
        "print(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4OX2FXYWV62",
        "colab_type": "text"
      },
      "source": [
        "**Comment on the traning and testing accuracies in the table above?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIgCwet8SjNR",
        "colab_type": "text"
      },
      "source": [
        "# Case #3: Recognition of Handwritten Digits\n",
        "\n",
        "In this section, we will try to recognize handwritten digits using **RandomForest** (RF). We will be using a standard dataset available through the sklearn library called \"load_digits\".$^{[1][2]}$\n",
        "\n",
        "[1] https://scikit-learn.org/stable/tutorial/basic/tutorial.html#introduction\n",
        "\n",
        "[2] https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html\n",
        "\n",
        "\n",
        "In the beginning, we will load the dataset as follows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thCgqt3KSpwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGRXkAwRMDWg",
        "colab_type": "text"
      },
      "source": [
        "A dataset is a dictionary-like object that holds all the data and some metadata about the data. Let us explore the content of the digits dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8qlgSoRTAhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir(digits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEbzkkNqMLZf",
        "colab_type": "text"
      },
      "source": [
        "The digits.data contains the features that will be used to classify the digits samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Lw41j9WUlr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(digits.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_ZbG54iNTgV",
        "colab_type": "text"
      },
      "source": [
        "The digits.images contains the images of the digits samples. They can be viewed using the following code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsM4ZMMWXGBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.gray()\n",
        "plt.matshow(digits.images[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK1cRXeTNmwf",
        "colab_type": "text"
      },
      "source": [
        "The ground truth of the datset is stored in the digits.taget"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX5YG-S-UxiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(digits.target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy6FObMY7yo2",
        "colab_type": "text"
      },
      "source": [
        "Let us use Principle Component Analysis to view the digits dataset. We will lot a projection on the 2 first principal axis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJA-IsUh7zxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "proj = pca.fit_transform(digits.data)\n",
        "plt.scatter(proj[:, 0], proj[:, 1], c=digits.target, cmap=\"Paired\")\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc0cKNwJN45-",
        "colab_type": "text"
      },
      "source": [
        "After exploring the content of the digits dataset, we will design a classified using **RF**. First, we decide the input feature vector (x) and the ground truth (y) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jSk9q-BU-1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = digits.data\n",
        "y = digits.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oti7Y9GiOg8M",
        "colab_type": "text"
      },
      "source": [
        "Then we split the datset into testing and training parts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBr_laJGVLRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)\n",
        "print('size of test dataset = {}, size of traing data = {}, percentage = {}%'.format(len(x_test),len(x_train),len(x_test)*100/(len(x_test) + len(x_train))))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9KDqCdXOn3M",
        "colab_type": "text"
      },
      "source": [
        "Here we will train the **RF** model and compute the accuracies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7QAzJ0pV6Am",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import ensemble\n",
        "model_rf = ensemble.RandomForestClassifier()\n",
        "model_rf.fit(x_train,y_train)\n",
        "ACC_train_rf = model_rf.score(x_train,y_train)\n",
        "ACC_test_rf = model_rf.score(x_test,y_test)\n",
        "print(ACC_train_rf)\n",
        "print(ACC_test_rf)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig8JsexROuls",
        "colab_type": "text"
      },
      "source": [
        "Let us try to compare **RF** with the other ML techqniues\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7Ya-2R5tE1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model_lr = LogisticRegression()\n",
        "model_lr.fit(x_train, y_train)\n",
        "ACC_train_lr = model_lr.score(x_train, y_train)\n",
        "ACC_test_lr = model_lr.score(x_test, y_test)\n",
        "\n",
        "## Decision Trees\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "model_dt = DecisionTreeClassifier()\n",
        "model_dt.fit(x_train, y_train)\n",
        "ACC_train_dt = model_dt.score(x_train, y_train)\n",
        "ACC_test_dt = model_dt.score(x_test, y_test)\n",
        "\n",
        "## Support Vector Machine\n",
        "from sklearn.svm import SVC \n",
        "model_svm = SVC()\n",
        "model_svm.fit(x_train, y_train)\n",
        "ACC_train_svm = model_svm.score(x_train, y_train)\n",
        "ACC_test_svm = model_svm.score(x_test, y_test)\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Accuracy', 'Logistic (%)' , 'DT (%)' , 'SVM (%)' , 'RF (%)'])\n",
        "t.add_row(['Training', ACC_train_lr*100, ACC_train_dt*100, ACC_train_svm*100, ACC_train_rf*100])\n",
        "t.add_row(['Testing', ACC_test_lr*100, ACC_test_dt*100, ACC_test_svm*100, ACC_test_rf*100])\n",
        "print(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf4y6xniXMj5",
        "colab_type": "text"
      },
      "source": [
        "**Comment on the training and testing accuracies in ther table above**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWgwLeKmuNo1",
        "colab_type": "text"
      },
      "source": [
        "To predict the types of test samples and store it is y_pred run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uyTP8bKWvFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model_rf.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnRMgtUVO-a1",
        "colab_type": "text"
      },
      "source": [
        "Sometimes, we wish to know where did the model fail. This can be achieved using what is called the confusion matrix (discussed in more details in logistic regression)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWjvAC3-ZNPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "\n",
        "import seaborn as sn\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(cm,annot=True)\n",
        "plt.xlabel('ground truth')\n",
        "plt.ylabel('predicted')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmyVn-epwhwg",
        "colab_type": "text"
      },
      "source": [
        "Let us try to find out how did the **RF** classified a specific digit. In the next code, we will visualize the images, predicted and target values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqHurAZyxBtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "fig = plt.figure(figsize=(12, 24))  # figure size in inches\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
        "\n",
        "digit_visualize = 5 # the digit that we want to visualize\n",
        "\n",
        "cnt = 0\n",
        "i = 0\n",
        "while (i < 128) and (i < len(y_test)) :\n",
        "    if y_test[i] == digit_visualize:\n",
        "       Idx = np.where(np.prod(digits.data == x_test[i,:],axis = -1))\n",
        "       ax = fig.add_subplot(16, 8, cnt + 1, xticks=[], yticks=[])\n",
        "       ax.imshow(digits.images[int(Idx[0])], cmap=plt.cm.binary, interpolation='nearest')\n",
        "       # label the image with the target value\n",
        "       ax.text(0, 7, str(y_test[i]))\n",
        "       ax.text(6.5, 7, str(y_pred[i]))\n",
        "       cnt+=1\n",
        "    i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQrgJCjB6o8d",
        "colab_type": "text"
      },
      "source": [
        "Let us try to find out in more details where did the **RF** failed. In the next code, we will visualize the images, predicted and target values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "410dhJlsewIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(12, 24))  # figure size in inches\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
        "\n",
        "cnt = 0\n",
        "i = 0\n",
        "while (i < 128) and (i < len(y_test)) :\n",
        "    if y_test[i] != y_pred[i]:\n",
        "       Idx = np.where(np.prod(digits.data == x_test[i,:],axis = -1))\n",
        "       ax = fig.add_subplot(16, 8, cnt + 1, xticks=[], yticks=[])\n",
        "       ax.imshow(digits.images[int(Idx[0])], cmap=plt.cm.binary, interpolation='nearest')\n",
        "       # label the image with the target value\n",
        "       ax.text(0, 7, str(y_test[i]))\n",
        "       ax.text(6.5, 7, str(y_pred[i]))\n",
        "       cnt+=1\n",
        "    i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQT1kr3qCsio",
        "colab_type": "text"
      },
      "source": [
        "# Case #4: Iris identification \n",
        "In this section, we will use **RF** classified to predict the type of the Iris based on its sepals and petals. Let us begin by loading the dataset from the sklearn library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVnkyeIFDL1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ME1QdoDlDwIW",
        "colab_type": "text"
      },
      "source": [
        "Let us get some information about the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHXDbXRfD1P7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir(iris)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnVgbrT_EXc4",
        "colab_type": "text"
      },
      "source": [
        "Let us explore the feature name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGke0yU_EbN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris.feature_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ3Z-E04Ehev",
        "colab_type": "text"
      },
      "source": [
        "So it contains information about the sepals. and petals. Let us also print the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZHPRrwYEyfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(iris.data[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9MizDd6E3rH",
        "colab_type": "text"
      },
      "source": [
        "so the data field includes the values of the features and in the same order. Let us also check the target and target_names of iris."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCqM8NBTFRYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(iris.target_names)\n",
        "print(iris.target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtdH9bK_Fom5",
        "colab_type": "text"
      },
      "source": [
        "So the target value is an encoding of each iris name based on the target_names field. Let us try to plot the features on scatter plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAtW7iSIHC-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df_iris['target'] = iris.target \n",
        "iris_0 = df_iris[df_iris.target==0]\n",
        "iris_1 = df_iris[df_iris.target==1]\n",
        "iris_2 = df_iris[df_iris.target==2]\n",
        "\n",
        "fig, axes = plt.subplots(2, 3,figsize = (10,7))\n",
        "axes[0,0].scatter(iris_0['sepal length (cm)'], iris_0['sepal width (cm)'] , color = 'blue' , marker = '+')\n",
        "axes[0,0].scatter(iris_1['sepal length (cm)'], iris_1['sepal width (cm)'] , color = 'red' , marker = 'x')\n",
        "axes[0,0].scatter(iris_2['sepal length (cm)'], iris_2['sepal width (cm)'] , color = 'green' , marker = 'o')\n",
        "axes[0,0].set_title('sepal length and sepal width')\n",
        "\n",
        "axes[0,1].scatter(iris_0['sepal length (cm)'], iris_0['petal length (cm)'] , color = 'blue' , marker = '+')\n",
        "axes[0,1].scatter(iris_1['sepal length (cm)'], iris_1['petal length (cm)'] , color = 'red' , marker = 'x')\n",
        "axes[0,1].scatter(iris_2['sepal length (cm)'], iris_2['petal length (cm)'] , color = 'green' , marker = 'o')\n",
        "axes[0,1].set_title('sepal length and petal length')\n",
        "\n",
        "axes[0,2].scatter(iris_0['sepal length (cm)'], iris_0['petal width (cm)'] , color = 'blue' , marker = '+')\n",
        "axes[0,2].scatter(iris_1['sepal length (cm)'], iris_1['petal width (cm)'] , color = 'red' , marker = 'x')\n",
        "axes[0,2].scatter(iris_2['sepal length (cm)'], iris_2['petal width (cm)'] , color = 'green' , marker = 'o')\n",
        "axes[0,2].set_title('sepal length and petal width')\n",
        "\n",
        "axes[1,0].scatter(iris_0['sepal width (cm)'], iris_0['petal length (cm)'] , color = 'blue' , marker = '+')\n",
        "axes[1,0].scatter(iris_1['sepal width (cm)'], iris_1['petal length (cm)'] , color = 'red' , marker = 'x')\n",
        "axes[1,0].scatter(iris_2['sepal width (cm)'], iris_2['petal length (cm)'] , color = 'green' , marker = 'o')\n",
        "axes[1,0].set_title('sepal width and petal width')\n",
        "\n",
        "axes[1,1].scatter(iris_0['sepal width (cm)'], iris_0['petal width (cm)'] , color = 'blue' , marker = '+')\n",
        "axes[1,1].scatter(iris_1['sepal width (cm)'], iris_1['petal width (cm)'] , color = 'red' , marker = 'x')\n",
        "axes[1,1].scatter(iris_2['sepal width (cm)'], iris_2['petal width (cm)'] , color = 'green' , marker = 'o')\n",
        "axes[1,1].set_title('sepal width and petal width')\n",
        "\n",
        "axes[1,2].scatter(iris_0['petal length (cm)'], iris_0['petal width (cm)'] , color = 'blue' , marker = '+')\n",
        "axes[1,2].scatter(iris_1['petal length (cm)'], iris_1['petal width (cm)'] , color = 'red' , marker = 'x')\n",
        "axes[1,2].scatter(iris_2['petal length (cm)'], iris_2['petal width (cm)'] , color = 'green' , marker = 'o')\n",
        "axes[1,2].set_title('petal length and petal width')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCrzKfzxGsJL",
        "colab_type": "text"
      },
      "source": [
        "It can be observed from these figures that the features of \"setosa\" are different than the other two iris (versicolor, virginica) and thus can be easily identified. The other two are separable using **RF** but errors might occur.\n",
        "\n",
        "Let us also use Principle Component Analysis to view the digits dataset. We will lot a projection on the 2 first principal axis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mgeIrBFF9_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "proj = pca.fit_transform(iris.data)\n",
        "plt.scatter(proj[:, 0], proj[:, 1], c=iris.target, cmap=\"Paired\")\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiCbgAd9OZkj",
        "colab_type": "text"
      },
      "source": [
        "Again, iris with target code 0 (setosa) is separated from the other two iris."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiWL8GGWPLwl",
        "colab_type": "text"
      },
      "source": [
        "Let us now define and split the dataset and then train the **RF** model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdlNP8UVPp0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## define input (x) and output (y)\n",
        "x = df_iris.drop('target',axis=1)\n",
        "y=df_iris.target\n",
        "\n",
        "## split dataset into training and testing datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)\n",
        "\n",
        "## train the RF model\n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "model_rf = RandomForestClassifier()\n",
        "model_rf.fit(x_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXN1hWdPSnaB",
        "colab_type": "text"
      },
      "source": [
        "The accuracy of this **RF** model is "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b0Rv6-vS9uF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ACC_train_rf = model_rf.score(x_train,y_train)\n",
        "ACC_test_rf = model_rf.score(x_test,y_test)\n",
        "print('Accuracy: traing = {}%, test = {}%'.format(ACC_train_rf*100,ACC_test_rf*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rhyn-fyRTaTC",
        "colab_type": "text"
      },
      "source": [
        "As expected (based on the features and PCA figures) the **RF** was able to classify the different iris types with high accuracy.\n",
        "\n",
        "Let us compare **RF** with the other ML techniques"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMrmkqAgwlI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model_lr = LogisticRegression()\n",
        "model_lr.fit(x_train, y_train)\n",
        "ACC_train_lr = model_lr.score(x_train, y_train)\n",
        "ACC_test_lr = model_lr.score(x_test, y_test)\n",
        "\n",
        "## Decision Trees\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "model_dt = DecisionTreeClassifier()\n",
        "model_dt.fit(x_train, y_train)\n",
        "ACC_train_dt = model_dt.score(x_train, y_train)\n",
        "ACC_test_dt = model_dt.score(x_test, y_test)\n",
        "\n",
        "## Support Vector Machine\n",
        "from sklearn.svm import SVC \n",
        "model_svm = SVC()\n",
        "model_svm.fit(x_train, y_train)\n",
        "ACC_train_svm = model_svm.score(x_train, y_train)\n",
        "ACC_test_svm = model_svm.score(x_test, y_test)\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Accuracy', 'Logistic (%)' , 'DT (%)' , 'SVM (%)' , 'RF (%)'])\n",
        "t.add_row(['Training', ACC_train_lr*100, ACC_train_dt*100, ACC_train_svm*100, ACC_train_rf*100])\n",
        "t.add_row(['Testing', ACC_test_lr*100, ACC_test_dt*100, ACC_test_svm*100, ACC_test_rf*100])\n",
        "print(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clLdKNnsVLSK",
        "colab_type": "text"
      },
      "source": [
        "# Exercises\n",
        "\n",
        "**Exercise #1**\n",
        "\n",
        "**Exercise #2**"
      ]
    }
  ]
}